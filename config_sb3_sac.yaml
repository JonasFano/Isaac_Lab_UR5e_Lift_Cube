# Reference: https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/sac.yml
program: train_sb3_wandb_sac.py
method: bayes
name: joint_pos_sb3_sac_ur5e_cube_lift
metric:
  goal: minimize
  name: train/loss

parameters:
  seed:
    value: 42

  n_timesteps: # iteration * n_steps * nenvs: 100 * 64 * 4096 = 26214400
    value: 13107200

  policy:
    value: 'MlpPolicy'


  batch_size:
    value: 256

  gamma:
    value: 0.99

  ent_coef: 
    value: "auto"

  learning_rate:
    value: 3e-4

  train_freq:
    value: 4

  gradient_steps:
    value: 4

  target_update_interval: 
    value: 1

  # target_entropy: -7 # - action space dimensions (3 translational components, 3 rotational components, 1 binary gripper)
  
  buffer_size: 
    value: 10000000

  learning_starts: 
    value: 1000

  tau: 
    value: 0.02

  use_sde: 
    value: True

  policy_kwargs:
    parameters:
      activation_fn: 
        value: nn.ELU
      net_arch:
        values: [[300, 300], [256, 128, 64]]


  normalize_input:
    value: True

  normalize_value:
    value: True

  clip_obs:
    value: 5