seed: 42


# Models are instantiated using skrl's model instantiator utility
# https://skrl.readthedocs.io/en/latest/api/utils/model_instantiators.html
models:
  separate: False
  policy:  # see gaussian_model parameters
    class: GaussianMixin
    clip_actions: False
    clip_log_std: True
    min_log_std: -20.0
    max_log_std: 2.0
    initial_log_std: 0.0
    network:
      - name: net
        input: STATES
        layers: [256, 128, 64]
        activations: elu
    output: ACTIONS
  value:  # see deterministic_model parameters
    class: DeterministicMixin
    clip_actions: False
    network:
      - name: net
        input: STATES
        layers: [256, 128, 64]
        activations: elu
    output: ONE


# Rollout memory
# https://skrl.readthedocs.io/en/latest/api/memories/random.html
memory:
  class: RandomMemory
  memory_size: -1  # automatically determined (same as agent:rollouts)


# PPO agent configuration (field names are from PPO_DEFAULT_CONFIG)
# https://skrl.readthedocs.io/en/latest/api/agents/ppo.html
agent:
  class: PPO

  # n_steps from sb3
  rollouts: 96 

  # n_epochs from sb3
  learning_epochs: 8 

  # Total collected data in each training iteration / batch_size
  mini_batches: 12 # 96 * 2048 / 98304 -> equation provided by skrl or use 96 * 2048 / batch_size (e.g. 16384)
  discount_factor: 0.99
  lambda: 0.95
  learning_rate: !!float 1e-3
  learning_rate_scheduler: KLAdaptiveLR
  learning_rate_scheduler_kwargs:
    kl_threshold: 0.01
    min_lr: !!float 1e-5
  state_preprocessor: RunningStandardScaler
  state_preprocessor_kwargs: null
  value_preprocessor: RunningStandardScaler
  value_preprocessor_kwargs: null
  random_timesteps: 0
  learning_starts: 0
  grad_norm_clip: 1.0
  ratio_clip: 0.2
  value_clip: 0.2
  clip_predicted_values: True
  entropy_loss_scale: 0.01
  value_loss_scale: 1.0
  kl_threshold: 0.0
  rewards_shaper_scale: 1.0
  time_limit_bootstrap: True
  # logging and checkpoint
  experiment:
    directory: "ppo/UR5e-Lift-Cube-IK"
    headless: True
    experiment_name: ""
    write_interval: auto
    checkpoint_interval: auto
    wandb: True
    wandb_kwargs:
      entity: jofan23-university-of-southern-denmark

# agent:
#   class: PPO
#   rollouts: 24
#   learning_epochs: 8
#   mini_batches: 4
#   discount_factor: 0.99
#   lambda: 0.95
#   learning_rate: 1.0e-04
#   learning_rate_scheduler: KLAdaptiveLR
#   learning_rate_scheduler_kwargs:
#     kl_threshold: 0.01
#   state_preprocessor: RunningStandardScaler
#   state_preprocessor_kwargs: null
#   value_preprocessor: RunningStandardScaler
#   value_preprocessor_kwargs: null
#   random_timesteps: 0
#   learning_starts: 0
#   grad_norm_clip: 1.0
#   ratio_clip: 0.2
#   value_clip: 0.2
#   clip_predicted_values: True
#   entropy_loss_scale: 0.001
#   value_loss_scale: 2.0
#   kl_threshold: 0.0
#   rewards_shaper_scale: 0.01
#   time_limit_bootstrap: False
#   # logging and checkpoint
#   experiment:
#     directory: "UR5e-Lift-Cube-IK"
#     experiment_name: ""
#     write_interval: auto
#     checkpoint_interval: auto


# Sequential trainer
# https://skrl.readthedocs.io/en/latest/api/trainers/sequential.html
trainer:
  class: SequentialTrainer
  timesteps: 104857600 # 98304
  environment_info: log
